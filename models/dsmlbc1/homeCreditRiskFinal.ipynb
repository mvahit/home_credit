{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/Users/mvahit/anaconda3/lib/python3.7/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-fd0b68c6476c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mlightgbm\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mgc\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m    140\u001B[0m     \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0m_distributor_init\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 142\u001B[0;31m     \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    143\u001B[0m     \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    144\u001B[0m     \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mcompat\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     72\u001B[0m         \u001B[0;34m\"numpy in {}. One method of fixing this is to repeatedly uninstall \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m         \"numpy until none is found, then reinstall this version.\")\n\u001B[0;32m---> 74\u001B[0;31m     \u001B[0;32mraise\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumerictypes\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: Something is wrong with the numpy installation. While importing we detected an older version of numpy in ['/Users/mvahit/anaconda3/lib/python3.7/site-packages/numpy']. One method of fixing this is to repeatedly uninstall numpy until none is found, then reinstall this version."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display/plot feature importance\n",
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:100].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize=(15, 20))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgbm_importances01.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                            \n",
      "                                                            \n",
      "                                                            \n",
      "                cience I_           cience I_               \n",
      "            a_Science I_Love_   a_Science I_Love_           \n",
      "          ta_Science I_Love_Data_Science I_Love_Dat         \n",
      "         ta_Science I_Love_Data_Science I_Love_Data_        \n",
      "        ta_Science I_Love_Data_Science I_Love_Data_Sc       \n",
      "        a_Science I_Love_Data_Science I_Love_Data_Sci       \n",
      "        _Science I_Love_Data_Science I_Love_Data_Scie       \n",
      "        Science I_Love_Data_Science I_Love_Data_Scien       \n",
      "        cience I_Love_Data_Science I_Love_Data_Scienc       \n",
      "        ience I_Love_Data_Science I_Love_Data_Science       \n",
      "         nce I_Love_Data_Science I_Love_Data_Science        \n",
      "          e I_Love_Data_Science I_Love_Data_Science         \n",
      "           I_Love_Data_Science I_Love_Data_Science          \n",
      "            Love_Data_Science I_Love_Data_Science           \n",
      "             ve_Data_Science I_Love_Data_Science            \n",
      "              _Data_Science I_Love_Data_Science             \n",
      "                ta_Science I_Love_Data_Scienc               \n",
      "                  Science I_Love_Data_Scien                 \n",
      "                    ence I_Love_Data_Scie                   \n",
      "                        I_Love_Data_Sc                      \n",
      "                          ove_Data_                         \n",
      "                             Dat                            \n",
      "                              t                             \n",
      "                                                            \n",
      "                                                            \n",
      "                                                            \n",
      "                                                            \n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([''.join([(' I_Love_Data_Science_'[(x-y) % len('I_Love_Data_Science_')] if ((x*0.05)**2+(y*0.1)**2-1)**3-(x*0.05)**2*(y*0.1)**3 <= 0 else ' ') for x in range(-30, 30)]) for y in range(15, -15, -1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# application_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def application_train():\n",
    "\n",
    "    df = pd.read_csv('data/application_train.csv')\n",
    "    test_df = pd.read_csv('data/application_test.csv')\n",
    "\n",
    "    df = df.append(test_df).reset_index()\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "    lbe = LabelEncoder()\n",
    "\n",
    "    for col in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "            df[col] = lbe.fit_transform(df[col])\n",
    "\n",
    "    df = pd.get_dummies(df, dummy_na = True)\n",
    "\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace = True)\n",
    "    df['NEW_DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['NEW_INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['NEW_INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['NEW_ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['NEW_PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "\n",
    "    df.drop(\"index\", axis = 1, inplace =  True)\n",
    "\n",
    "    df.columns = pd.Index([\"APP_\" + col for col in df.columns.tolist()])\n",
    "\n",
    "    df.rename(columns={\"APP_SK_ID_CURR\":\"SK_ID_CURR\"}, inplace = True)\n",
    "\n",
    "    df.rename(columns={\"APP_TARGET\":\"TARGET\"}, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bureau & bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bureau_bb():\n",
    "\n",
    "    #bureau_balance tablosunun okutulması\n",
    "\n",
    "    bb = pd.read_csv('data/bureau_balance.csv')\n",
    "    bb = pd.get_dummies(bb, dummy_na = True)\n",
    "\n",
    "    agg_list = {\"MONTHS_BALANCE\":\"count\",\n",
    "                \"STATUS_0\":[\"sum\",\"mean\"],\n",
    "                \"STATUS_1\":[\"sum\"],\n",
    "                \"STATUS_2\":[\"sum\"],\n",
    "                \"STATUS_3\":[\"sum\"],\n",
    "                \"STATUS_4\":[\"sum\"],\n",
    "                \"STATUS_5\":[\"sum\"],\n",
    "                \"STATUS_C\":[\"sum\",\"mean\"],\n",
    "                \"STATUS_X\":[\"sum\",\"mean\"] }\n",
    "\n",
    "    bb_agg = bb.groupby(\"SK_ID_BUREAU\").agg(agg_list)\n",
    "\n",
    "    # Degisken isimlerinin yeniden adlandirilmasi \n",
    "    bb_agg.columns = pd.Index([col[0] + \"_\" + col[1].upper() for col in bb_agg.columns.tolist()])\n",
    "\n",
    "    # Status_sum ile ilgili yeni bir degisken olusturma\n",
    "    bb_agg['NEW_STATUS_SCORE'] = bb_agg['STATUS_1_SUM'] + bb_agg['STATUS_2_SUM']^2 + bb_agg['STATUS_3_SUM']^3 + bb_agg['STATUS_4_SUM']^4 + bb_agg['STATUS_5_SUM']^5\n",
    "\n",
    "    bb_agg.drop(['STATUS_1_SUM','STATUS_2_SUM','STATUS_3_SUM','STATUS_4_SUM','STATUS_5_SUM'], axis=1,inplace=True)\n",
    "\n",
    "    bureau = pd.read_csv('data/bureau.csv')\n",
    "    bureau_and_bb = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "\n",
    "    #BUREAU BALANCE VE BUREAU ORTAK TABLO\n",
    "\n",
    "    #CREDIT_TYPE degiskeninin sinif sayisini 3'e düsürmek \n",
    "    bureau_and_bb['CREDIT_TYPE'] = bureau_and_bb['CREDIT_TYPE'].replace(['Car loan',\n",
    "              'Mortgage',\n",
    "              'Microloan',\n",
    "              'Loan for business development', \n",
    "              'Another type of loan',\n",
    "              'Unknown type of loan', \n",
    "              'Loan for working capital replenishment',\n",
    "              \"Loan for purchase of shares (margin lending)\",                                                \n",
    "              'Cash loan (non-earmarked)', \n",
    "              'Real estate loan',\n",
    "              \"Loan for the purchase of equipment\", \n",
    "              \"Interbank credit\", \n",
    "              \"Mobile operator loan\"], 'Rare')\n",
    "\n",
    "\n",
    "    #CREDIT_ACTIVE degiskeninin sinif sayisini 2'ye düsürmek (Sold' u Closed a dahil etmek daha mi uygun olur ???)\n",
    "    bureau_and_bb['CREDIT_ACTIVE'] = bureau_and_bb['CREDIT_ACTIVE'].replace(['Bad debt','Sold'], 'Active')\n",
    "\n",
    "    # bureau_bb tablosundaki kategorik degiskenlere One Hot Encoding uygulanmasi\n",
    "    bureau_and_bb = pd.get_dummies(bureau_and_bb, columns = [\"CREDIT_TYPE\",\"CREDIT_ACTIVE\"])\n",
    "\n",
    "    # CREDIT_CURRENCY degiskeninin %99u currency1, bu sebeple ayirt ediciligi olmayacagini dusundugumuz icin sildik  \n",
    "    bureau_and_bb.drop([\"SK_ID_BUREAU\",\"CREDIT_CURRENCY\"], inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "    #NEW FEATURES\n",
    "\n",
    "    #ortalama kac aylık kredi aldıgını gösteren yeni degisken\n",
    "    bureau_and_bb[\"NEW_MONTHS_CREDIT\"]= round((bureau_and_bb.DAYS_CREDIT_ENDDATE - bureau_and_bb.DAYS_CREDIT)/30)\n",
    "\n",
    "    agg_list = {\n",
    "          \"SK_ID_CURR\":[\"count\"],\n",
    "          \"DAYS_CREDIT\":[\"min\",\"max\"],\n",
    "          \"CREDIT_DAY_OVERDUE\":[\"sum\",\"mean\",\"max\"],     \n",
    "          \"DAYS_CREDIT_ENDDATE\":[\"max\",\"min\"],\n",
    "          \"DAYS_ENDDATE_FACT\":[\"max\",\"min\"],\n",
    "          \"AMT_CREDIT_MAX_OVERDUE\":[\"mean\",\"max\",\"min\"],\n",
    "          \"CNT_CREDIT_PROLONG\":[\"sum\",\"mean\",\"max\",\"min\"],\n",
    "          \"AMT_CREDIT_SUM\":[\"mean\",\"max\",\"min\"],            \n",
    "          \"AMT_CREDIT_SUM_DEBT\":[\"sum\",\"mean\",\"max\"],\n",
    "          \"AMT_CREDIT_SUM_LIMIT\":[\"sum\",\"mean\",\"max\"],\n",
    "          'AMT_CREDIT_SUM_OVERDUE':[\"sum\",\"mean\",\"max\"], \n",
    "          'DAYS_CREDIT_UPDATE':[\"max\",\"min\"],\n",
    "          'AMT_ANNUITY':[\"sum\",\"mean\"],\n",
    "          'MONTHS_BALANCE_COUNT':[\"sum\"], \n",
    "          'STATUS_0_SUM':[\"sum\"],         \n",
    "          'STATUS_0_MEAN':[\"mean\"], \n",
    "          'STATUS_C_SUM':[\"sum\"], \n",
    "          'STATUS_C_MEAN':[\"mean\"],\n",
    "          'CREDIT_ACTIVE_Active':[\"sum\",\"mean\"], \n",
    "          'CREDIT_ACTIVE_Closed':[\"sum\",\"mean\"], \n",
    "          'CREDIT_TYPE_Rare':[\"sum\",\"mean\"],      \n",
    "          'CREDIT_TYPE_Consumer credit':[\"sum\",\"mean\"], \n",
    "          'CREDIT_TYPE_Credit card':[\"sum\",\"mean\"],\n",
    "          \"NEW_MONTHS_CREDIT\":[\"count\",\"sum\",\"mean\",\"max\",\"min\"]}\n",
    "\n",
    "\n",
    "    # bureau_bb_agg tablosuna aggreagation islemlerinin uygulanamasi  \n",
    "    bureau_and_bb_agg = bureau_and_bb.groupby(\"SK_ID_CURR\").agg(agg_list).reset_index()\n",
    "\n",
    "\n",
    "    # Degisken isimlerinin yeniden adlandirilmasi \n",
    "    bureau_and_bb_agg.columns = pd.Index([\"BB_\" + col[0] + \"_\" + col[1].upper() for col in bureau_and_bb_agg.columns.tolist()])\n",
    "\n",
    "    # kisinin aldıgı en yuksek ve en dusuk kredinin farkını gösteren yeni degisken\n",
    "    bureau_and_bb_agg[\"BB_NEW_AMT_CREDIT_SUM_RANGE\"] = bureau_and_bb_agg[\"BB_AMT_CREDIT_SUM_MAX\"] - bureau_and_bb_agg[\"BB_AMT_CREDIT_SUM_MIN\"]\n",
    "\n",
    "    # ortalama kac ayda bir kredi cektigini ifade eden  yeni degisken\n",
    "    bureau_and_bb_agg[\"BB_NEW_DAYS_CREDIT_RANGE\"]= round((bureau_and_bb_agg[\"BB_DAYS_CREDIT_MAX\"] - bureau_and_bb_agg[\"BB_DAYS_CREDIT_MIN\"])/(30 * bureau_and_bb_agg[\"BB_SK_ID_CURR_COUNT\"]))\n",
    "\n",
    "\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    agg_list = {\n",
    "            'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "            'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "            'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "            'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "            'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "            'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "            'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "            'AMT_ANNUITY': ['max', 'mean'],\n",
    "            'CNT_CREDIT_PROLONG': ['sum']\n",
    "        }\n",
    "\n",
    "\n",
    "    active = bureau_and_bb[bureau_and_bb['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(agg_list)\n",
    "    active_agg.columns = pd.Index(['BB_NEW_ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_and_bb_agg.rename(columns = {'BB_SK_ID_CURR_': 'SK_ID_CURR'}, inplace = True)\n",
    "    bureau_and_bb_agg = bureau_and_bb_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau_and_bb[bureau_and_bb['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(agg_list)\n",
    "    closed_agg.columns = pd.Index(['BB_NEW_CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_and_bb_agg = bureau_and_bb_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    \n",
    "    return bureau_and_bb_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def installments_payments():\n",
    "\n",
    "    #Read the installments_payments.csv\n",
    "    ins = pd.read_csv('data/installments_payments.csv')\n",
    "\n",
    "    ins['NEW_DAYS_PAID_EARLIER'] = ins['DAYS_INSTALMENT']-ins['DAYS_ENTRY_PAYMENT']\n",
    "\n",
    "    # Her bir taksit ödemesinin gec olup olmama durumu 1: gec ödedi 0: erken ödemeyi temsil eder\n",
    "    ins['NEW_NUM_PAID_LATER'] = ins['NEW_DAYS_PAID_EARLIER'].map(lambda x: 1 if x<0 else 0)\n",
    "\n",
    "    # Agrregation ve degisken tekillestirme\n",
    "    agg_list = {'NUM_INSTALMENT_VERSION':['nunique'],\n",
    "               'NUM_INSTALMENT_NUMBER':'max',\n",
    "               'DAYS_INSTALMENT':['min','max'],\n",
    "               'DAYS_ENTRY_PAYMENT':['min','max'],\n",
    "               'AMT_INSTALMENT':['min','max','sum','mean'],\n",
    "               'AMT_PAYMENT':['min','max','sum','mean'],\n",
    "               'NEW_DAYS_PAID_EARLIER':'mean',\n",
    "               'NEW_NUM_PAID_LATER':'sum'}\n",
    "\n",
    "\n",
    "    ins_agg = ins.groupby('SK_ID_PREV').agg(agg_list)\n",
    "\n",
    "\n",
    "    # Multi index problemi cözümü\n",
    "    ins_agg.columns = pd.Index([\"INS_\" + e[0] + '_' + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "\n",
    "    # drop variables \n",
    "    ins_agg.drop(['INS_DAYS_INSTALMENT_MIN',\n",
    "                   'INS_DAYS_INSTALMENT_MAX',\n",
    "                   'INS_DAYS_ENTRY_PAYMENT_MIN',\n",
    "                   'INS_DAYS_ENTRY_PAYMENT_MAX'],axis=1,inplace=True)\n",
    "\n",
    "    # Kredi ödeme yüzdesi ve toplam kalan borc\n",
    "    ins_agg['INS_NEW_PAYMENT_PERC'] = ins_agg['INS_AMT_PAYMENT_SUM'] / ins_agg['INS_AMT_INSTALMENT_SUM']\n",
    "    ins_agg['INS_NEW_PAYMENT_DIFF'] = ins_agg['INS_AMT_INSTALMENT_SUM'] - ins_agg['INS_AMT_PAYMENT_SUM']\n",
    "    \n",
    "    agg_list_previous_application = {}\n",
    "    \n",
    "    for col in ins_agg.columns:\n",
    "        agg_list_previous_application[col] = ['mean',\"min\",\"max\",\"sum\"]\n",
    "    \n",
    "    ins_agg.reset_index(inplace = True) \n",
    "    \n",
    "    return agg_list_previous_application, ins_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pos_cash_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_cash_balance(agg_list_previous_application):\n",
    "\n",
    "    pos = pd.read_csv('data/POS_CASH_balance.csv')\n",
    "    # Kategorik Degiskenimizi Dummy Degiskenine Dönüstürme\n",
    "    pos = pd.get_dummies(pos, columns=['NAME_CONTRACT_STATUS'], dummy_na = True)\n",
    "    # Aggregation Islemi - Tekillestirme\n",
    "    agg_list = {'MONTHS_BALANCE':['min','max'],\n",
    "                                            'CNT_INSTALMENT':['min','max'],\n",
    "                                            'CNT_INSTALMENT_FUTURE':['min','max'],\n",
    "                                            'SK_DPD':['max','mean'],\n",
    "                                            'SK_DPD_DEF':['max','mean'],\n",
    "                                            'NAME_CONTRACT_STATUS_Active':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_Amortized debt':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_Approved':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_Canceled':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_Completed':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_Demand':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_Returned to the store':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_Signed':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_XNA':'sum',\n",
    "                                            'NAME_CONTRACT_STATUS_nan':'sum'\n",
    "                                          }\n",
    "\n",
    "    pos_agg = pos.groupby('SK_ID_PREV').agg(agg_list)\n",
    "\n",
    "    # Multilayer index'i tek boyutlu index'e dönüstürme\n",
    "    pos_agg.columns= pd.Index([\"POS_\" + e[0] + '_' + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "\n",
    "    # SK_DPD kac kredide 0 olma durumu (SK_DPD MAX alacagiz 0 durumunu veriyor) \n",
    "    # SK_DPD_DEF (SK_DPD_DEF_MAX sifir olma durumunu veriyor)\n",
    "    # CNT_INSTALMENT_FUTURE_MIN==0 oldugunda NAME_CONTRACT_STATUS_Completed_SUM==0 olma durumu \n",
    "\n",
    "    pos_agg['POS_NEW_IS_CREDIT_NOT_COMPLETED_ON_TIME']= (pos_agg['POS_CNT_INSTALMENT_FUTURE_MIN']==0) & (pos_agg['POS_NAME_CONTRACT_STATUS_Completed_SUM']==0)\n",
    "\n",
    "\n",
    "    # 1:kredi zamaninda kapanmamis 0:kredi zamaninda kapanmis\n",
    "\n",
    "    pos_agg['POS_NEW_IS_CREDIT_NOT_COMPLETED_ON_TIME']=pos_agg['POS_NEW_IS_CREDIT_NOT_COMPLETED_ON_TIME'].astype(int)\n",
    "\n",
    "    pos_agg.drop(['POS_NAME_CONTRACT_STATUS_Approved_SUM',\n",
    "                   'POS_NAME_CONTRACT_STATUS_Amortized debt_SUM',\n",
    "                   'POS_NAME_CONTRACT_STATUS_Canceled_SUM',\n",
    "                   'POS_NAME_CONTRACT_STATUS_Returned to the store_SUM',\n",
    "                   'POS_NAME_CONTRACT_STATUS_Signed_SUM',\n",
    "                   'POS_NAME_CONTRACT_STATUS_XNA_SUM',\n",
    "                   'POS_NAME_CONTRACT_STATUS_nan_SUM'],axis=1,inplace=True)\n",
    "\n",
    "    for col in pos_agg.columns:\n",
    "        agg_list_previous_application[col] = ['mean',\"min\",\"max\",\"sum\"]\n",
    "\n",
    "    pos_agg.reset_index(inplace = True)     \n",
    "    \n",
    "    return agg_list_previous_application, pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def credit_card_balance():\n",
    "\n",
    "    CCB = pd.read_csv('data/credit_card_balance.csv')\n",
    "\n",
    "    CCB = pd.get_dummies(CCB, columns= ['NAME_CONTRACT_STATUS'] )  # artik tumu sayisal \n",
    "\n",
    "    dropthis = ['NAME_CONTRACT_STATUS_Approved', 'NAME_CONTRACT_STATUS_Demand',\n",
    "           'NAME_CONTRACT_STATUS_Refused', 'NAME_CONTRACT_STATUS_Sent proposal',\n",
    "           'NAME_CONTRACT_STATUS_Signed' ]\n",
    "\n",
    "    CCB = CCB.drop(dropthis, axis=1)\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR'])['SK_ID_PREV'].nunique().reset_index().rename(index = str, columns = {'SK_ID_PREV': 'NUMBER_OF_LOANS_PER_CUSTOMER'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR', 'SK_ID_PREV'])['CNT_INSTALMENT_MATURE_CUM'].max().reset_index().rename(index = str, columns = {'CNT_INSTALMENT_MATURE_CUM': 'NUMBER_OF_INSTALMENTS'})\n",
    "    grp1 = grp.groupby(by = ['SK_ID_CURR'])['NUMBER_OF_INSTALMENTS'].sum().reset_index().rename(index = str, columns = {'NUMBER_OF_INSTALMENTS': 'TOTAL_INSTALMENTS_OF_ALL_LOANS'})\n",
    "    CCB = CCB.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "    CCB['INSTALLMENTS_PER_LOAN'] = (CCB['TOTAL_INSTALMENTS_OF_ALL_LOANS']/CCB['NUMBER_OF_LOANS_PER_CUSTOMER']).astype('uint32')\n",
    "\n",
    "\n",
    "    # Bu fonksiyon, kac defa odemelerin geciktigini hesaplar\n",
    "    # Function to calculate number of times Days Past Due occurred\n",
    "    def geciken_gun_hesapla(DPD):\n",
    "\n",
    "        # DPD ile beklenen bir seri: SK_DPD degiskeninin her bir prev_app daki gecmis kredi icin olan degerleri\n",
    "        # DPD is a series of values of SK_DPD for each of the groupby combination\n",
    "        # We convert it to a list to get the number of SK_DPD values NOT EQUALS ZERO\n",
    "        x = DPD.tolist()\n",
    "        c = 0\n",
    "        for i,j in enumerate(x):\n",
    "            if j != 0:\n",
    "                c += 1  \n",
    "        return c \n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR', 'SK_ID_PREV']).apply(lambda x: geciken_gun_hesapla(x.SK_DPD)).reset_index().rename(index = str, columns = {0: 'NUMBER_OF_DPD'})\n",
    "    grp1 = grp.groupby(by = ['SK_ID_CURR'])['NUMBER_OF_DPD'].mean().reset_index().rename(index = str, columns = {'NUMBER_OF_DPD' : 'DPD_COUNT'})\n",
    "\n",
    "    CCB = CCB.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "\n",
    "    def f(min_pay, total_pay):\n",
    "\n",
    "        M = min_pay.tolist()\n",
    "        T = total_pay.tolist()\n",
    "        P = len(M)        # P: taksit sayisi\n",
    "        c = 0 \n",
    "        # Find the count of transactions when Payment made is less than Minimum Payment \n",
    "        for i in range(len(M)):\n",
    "            if T[i] < M[i]:\n",
    "                c += 1  \n",
    "        return (100*c)/P\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR']).apply(lambda x: f(x.AMT_INST_MIN_REGULARITY, x.AMT_PAYMENT_CURRENT)).reset_index().rename(index = str, columns = { 0 : 'PERCENTAGE_MIN_MISSED_PAYMENTS'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR'])['AMT_DRAWINGS_ATM_CURRENT'].sum().reset_index().rename(index = str, columns = {'AMT_DRAWINGS_ATM_CURRENT' : 'DRAWINGS_ATM'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR'])['AMT_DRAWINGS_CURRENT'].sum().reset_index().rename(index = str, columns = {'AMT_DRAWINGS_CURRENT' : 'DRAWINGS_TOTAL'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "\n",
    "    CCB['CASH_CARD_RATIO1'] = (CCB['DRAWINGS_ATM']/CCB['DRAWINGS_TOTAL'])*100  # ATM den cektigi nakit / toplam cektigi\n",
    "    del CCB['DRAWINGS_ATM']\n",
    "    del CCB['DRAWINGS_TOTAL']\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR'])['CASH_CARD_RATIO1'].mean().reset_index().rename(index = str, columns ={ 'CASH_CARD_RATIO1' : 'CASH_CARD_RATIO'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR'])['AMT_DRAWINGS_CURRENT'].sum().reset_index().rename(index = str, columns = {'AMT_DRAWINGS_CURRENT' : 'TOTAL_DRAWINGS'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR'])['CNT_DRAWINGS_CURRENT'].sum().reset_index().rename(index = str, columns = {'CNT_DRAWINGS_CURRENT' : 'NUMBER_OF_DRAWINGS'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "\n",
    "    CCB['DRAWINGS_RATIO1'] = (CCB['TOTAL_DRAWINGS']/CCB['NUMBER_OF_DRAWINGS'])*100     # yuzdelik degil, genisleme yapmis\n",
    "    del CCB['TOTAL_DRAWINGS']\n",
    "    del CCB['NUMBER_OF_DRAWINGS']\n",
    "\n",
    "\n",
    "    grp = CCB.groupby(by = ['SK_ID_CURR'])['DRAWINGS_RATIO1'].mean().reset_index().rename(index = str, columns ={ 'DRAWINGS_RATIO1' : 'DRAWINGS_RATIO'})\n",
    "    CCB = CCB.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "\n",
    "    del CCB['DRAWINGS_RATIO1']\n",
    "\n",
    "    CCB['CC_COUNT'] = CCB.groupby('SK_ID_CURR').size()\n",
    "\n",
    "    CCB_agg = CCB.groupby('SK_ID_CURR').agg({\n",
    "        'MONTHS_BALANCE':[\"sum\",\"mean\"], \n",
    "        'AMT_BALANCE':[\"sum\",\"mean\",\"min\",\"max\"],\n",
    "        'AMT_CREDIT_LIMIT_ACTUAL':[\"sum\",\"mean\"], \n",
    "\n",
    "        'AMT_DRAWINGS_ATM_CURRENT':[\"sum\",\"mean\",\"min\",\"max\"],\n",
    "        'AMT_DRAWINGS_CURRENT':[\"sum\",\"mean\",\"min\",\"max\"], \n",
    "        'AMT_DRAWINGS_OTHER_CURRENT':[\"sum\",\"mean\",\"min\",\"max\"],\n",
    "        'AMT_DRAWINGS_POS_CURRENT':[\"sum\",\"mean\",\"min\",\"max\"], \n",
    "        'AMT_INST_MIN_REGULARITY':[\"sum\",\"mean\",\"min\",\"max\"],\n",
    "        'AMT_PAYMENT_CURRENT':[\"sum\",\"mean\",\"min\",\"max\"], \n",
    "        'AMT_PAYMENT_TOTAL_CURRENT':[\"sum\",\"mean\",\"min\",\"max\"],\n",
    "        'AMT_RECEIVABLE_PRINCIPAL':[\"sum\",\"mean\",\"min\",\"max\"], \n",
    "        'AMT_RECIVABLE':[\"sum\",\"mean\",\"min\",\"max\"], \n",
    "        'AMT_TOTAL_RECEIVABLE':[\"sum\",\"mean\",\"min\",\"max\"],\n",
    "\n",
    "        'CNT_DRAWINGS_ATM_CURRENT':[\"sum\",\"mean\"], \n",
    "        'CNT_DRAWINGS_CURRENT':[\"sum\",\"mean\",\"max\"],\n",
    "        'CNT_DRAWINGS_OTHER_CURRENT':[\"mean\",\"max\"], \n",
    "        'CNT_DRAWINGS_POS_CURRENT':[\"sum\",\"mean\",\"max\"],\n",
    "        'CNT_INSTALMENT_MATURE_CUM':[\"sum\",\"mean\",\"max\",\"min\"],    \n",
    "        'SK_DPD':[\"sum\",\"mean\",\"max\"], \n",
    "        'SK_DPD_DEF':[\"sum\",\"mean\",\"max\"],\n",
    "\n",
    "        'NAME_CONTRACT_STATUS_Active':[\"sum\",\"mean\",\"min\",\"max\"], \n",
    "        'INSTALLMENTS_PER_LOAN':[\"sum\",\"mean\",\"min\",\"max\"],\n",
    "\n",
    "        'NUMBER_OF_LOANS_PER_CUSTOMER':[\"mean\"], \n",
    "        'DPD_COUNT':[\"mean\"],\n",
    "        'PERCENTAGE_MIN_MISSED_PAYMENTS':[\"mean\"], \n",
    "        'CASH_CARD_RATIO':[\"mean\"], \n",
    "        'DRAWINGS_RATIO':[\"mean\"]})\n",
    "\n",
    "\n",
    "    CCB_agg.columns = pd.Index(['CCB_' + e[0] + \"_\" + e[1].upper() for e in CCB_agg.columns.tolist()])\n",
    "\n",
    "    CCB_agg.reset_index(inplace = True)\n",
    "    \n",
    "    return CCB_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# previous_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previous_application(agg_list_previous_application):\n",
    "\n",
    "\n",
    "    df_prev = pd.read_csv('data/previous_application.csv')\n",
    "\n",
    "    # \"WEEKDAY_APPR_PROCESS_START\"  değişkeninin  WEEK_DAY ve WEEKEND olarak iki kategoriye ayrılması\n",
    "\n",
    "    df_prev[\"WEEKDAY_APPR_PROCESS_START\"] = df_prev[\"WEEKDAY_APPR_PROCESS_START\"].replace(['MONDAY','TUESDAY', 'WEDNESDAY','THURSDAY','FRIDAY'], 'WEEK_DAY')\n",
    "    df_prev[\"WEEKDAY_APPR_PROCESS_START\"] = df_prev[\"WEEKDAY_APPR_PROCESS_START\"].replace(['SATURDAY', 'SUNDAY'], 'WEEKEND')\n",
    "\n",
    "    # \"HOUR_APPR_PROCESS_START\"  değişkeninin working_hours ve off_hours olarak iki kategoriye ayrılması\n",
    "    a = [8,9,10,11,12,13,14,15,16,17]\n",
    "    df_prev[\"HOUR_APPR_PROCESS_START\"] = df_prev[\"HOUR_APPR_PROCESS_START\"].replace(a, 'working_hours')\n",
    "\n",
    "    b = [18,19,20,21,22,23,0,1,2,3,4,5,6,7]\n",
    "    df_prev[\"HOUR_APPR_PROCESS_START\"] = df_prev[\"HOUR_APPR_PROCESS_START\"].replace(b, 'off_hours')\n",
    "\n",
    "\n",
    "    # DAYS_DECISION değeri 1 yıldan küçük olanlara 1, büyük olanlara 0 değeri verildi.\n",
    "    df_prev[\"DAYS_DECISION\"] = [1 if abs(i/(12*30)) <=1 else 0 for i in df_prev.DAYS_DECISION]\n",
    "\n",
    "    # \"NAME_TYPE_SUITE\"  değişkeninin alone ve not_alone olarak iki kategoriye ayrılması\n",
    "\n",
    "    df_prev[\"NAME_TYPE_SUITE\"] = df_prev[\"NAME_TYPE_SUITE\"].replace('Unaccompanied', 'alone')\n",
    "\n",
    "    b = ['Family', 'Spouse, partner', 'Children', 'Other_B', 'Other_A', 'Group of people']\n",
    "    df_prev[\"NAME_TYPE_SUITE\"] = df_prev[\"NAME_TYPE_SUITE\"].replace(b, 'not_alone')\n",
    "\n",
    "\n",
    "\n",
    "    # \"NAME_GOODS_CATEGORY\"  değişkenindeki bu değerler others olarak kategorize edilecek\n",
    "    a = ['Auto Accessories', 'Jewelry', 'Homewares', 'Medical Supplies', 'Vehicles', 'Sport and Leisure', \n",
    "         'Gardening', 'Other', 'Office Appliances', 'Tourism', 'Medicine', 'Direct Sales', 'Fitness', 'Additional Service', \n",
    "         'Education', 'Weapon', 'Insurance', 'House Construction', 'Animals'] \n",
    "    df_prev[\"NAME_GOODS_CATEGORY\"] = df_prev[\"NAME_GOODS_CATEGORY\"].replace(a, 'others')\n",
    "\n",
    "    # \"NAME_SELLER_INDUSTRY\"  değişkenindeki bu değerler others olarak kategorize edilecek\n",
    "    a = ['Auto technology', 'Jewelry', 'MLM partners', 'Tourism'] \n",
    "    df_prev[\"NAME_SELLER_INDUSTRY\"] = df_prev[\"NAME_SELLER_INDUSTRY\"].replace(a, 'others')\n",
    "    # İstenilen krecinin verilen krediye oranı içeren değişkeni türetir\n",
    "    df_prev[\"LOAN_RATE\"] = df_prev.AMT_APPLICATION/df_prev.AMT_CREDIT\n",
    "\n",
    "    #YENI DEGISKENLER\n",
    "\n",
    "    # İstenilen krecinin verilen krediye oranı içeren değişkeni türetir\n",
    "    df_prev[\"NEW_LOAN_RATE\"] = df_prev.AMT_APPLICATION/df_prev.AMT_CREDIT\n",
    "\n",
    "    # Ödeme gününü geciktirmiş mi bunu gösteren churn_prev değişkeni türetilir.\n",
    "    # 1= geciktirmiş, 0 = geciktirmemiş, NaN = boş değer\n",
    "    k = df_prev.DAYS_LAST_DUE_1ST_VERSION - df_prev.DAYS_LAST_DUE\n",
    "    df_prev[\"NEW_CHURN_PREV\"] = [1 if i >= 0 else (0 if i < 0  else \"NaN\") for i in k]\n",
    "\n",
    "\n",
    "    # NFLAG_INSURED_ON_APPROVAL değişkeni yerine kullanılmak izere NEW_INSURANCE değişkeni tanımlandı.\n",
    "    df_prev[(df_prev['AMT_CREDIT'] == 0) | (df_prev['AMT_GOODS_PRICE'] == 0)]['NEW_INSURANCE'] = np.nan\n",
    "    df_prev['sigorta_miktari'] = df_prev['AMT_CREDIT'] - df_prev['AMT_GOODS_PRICE']\n",
    "    df_prev[\"NEW_INSURANCE\"] = df_prev['sigorta_miktari'].apply(lambda x: 1 if x > 0 else (0 if x <= 0 else np.nan))\n",
    "    df_prev.drop('sigorta_miktari', axis=1, inplace=True)\n",
    "\n",
    "    # INTEREST_RATE değişkenini oluşturur.\n",
    "    #df_prev['INTEREST_RATE'] = (df_prev.AMT_ANNUITY*df_prev.CNT_PAYMENT/df_prev.AMT_CREDIT)**(12/df_prev.CNT_PAYMENT)-1\n",
    "    #df_prev[df_prev['INTEREST_RATE']==-1]=np.nan\n",
    "\n",
    "\n",
    "    drop_list = ['AMT_DOWN_PAYMENT', 'SELLERPLACE_AREA', 'CNT_PAYMENT', 'PRODUCT_COMBINATION', 'DAYS_FIRST_DRAWING', 'DAYS_FIRST_DUE',\n",
    "                'DAYS_LAST_DUE_1ST_VERSION', 'DAYS_LAST_DUE','DAYS_TERMINATION','NFLAG_INSURED_ON_APPROVAL']\n",
    "    df_prev.drop(drop_list, axis = 1, inplace = True)\n",
    "\n",
    "    # Previous tablosundaki kategorik değişkenlerin isimlerini tutar.\n",
    "    category_columns=[]\n",
    "    for i in df_prev.columns:\n",
    "        if df_prev[i].dtypes == \"O\":\n",
    "            category_columns.append(i)\n",
    "\n",
    "    df_prev = pd.get_dummies(df_prev, columns = category_columns )\n",
    "\n",
    "    prev_agg_list = {\"SK_ID_CURR\":[\"count\"], \n",
    "                \"AMT_ANNUITY\":[\"max\"],\n",
    "                \"AMT_APPLICATION\":[\"min\",\"mean\",\"max\"],\n",
    "                \"AMT_CREDIT\":[\"max\"], \n",
    "                \"AMT_GOODS_PRICE\":[\"sum\", \"mean\"],\n",
    "                \"NFLAG_LAST_APPL_IN_DAY\":[\"sum\",\"mean\"], \n",
    "                \"RATE_DOWN_PAYMENT\":[\"sum\", \"mean\"],\n",
    "                \"RATE_INTEREST_PRIMARY\":[\"sum\", \"mean\"],\n",
    "                \"RATE_INTEREST_PRIVILEGED\":[\"sum\", \"mean\"],\n",
    "                \"DAYS_DECISION\":[\"sum\"],\n",
    "                \"NEW_LOAN_RATE\":[\"sum\", \"mean\", \"min\", \"max\"],\n",
    "                \"NEW_INSURANCE\":[\"sum\", \"mean\"],\n",
    "                #\"INTEREST_RATE\":[\"sum\", \"mean\", \"min\", \"max\"],\n",
    "                \"NAME_CONTRACT_TYPE_Cash loans\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CONTRACT_TYPE_Consumer loans\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CONTRACT_TYPE_Revolving loans\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CONTRACT_TYPE_XNA\":[\"sum\", \"mean\"],\n",
    "                \"WEEKDAY_APPR_PROCESS_START_WEEKEND\":[\"sum\", \"mean\"],\n",
    "                \"WEEKDAY_APPR_PROCESS_START_WEEK_DAY\":[\"sum\", \"mean\"],\n",
    "                \"HOUR_APPR_PROCESS_START_off_hours\":[\"sum\", \"mean\"],\n",
    "                \"HOUR_APPR_PROCESS_START_working_hours\":[\"sum\", \"mean\"],\n",
    "                \"FLAG_LAST_APPL_PER_CONTRACT_N\":[\"sum\", \"mean\"],\n",
    "                \"FLAG_LAST_APPL_PER_CONTRACT_Y\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Building a house or an annex\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Business development\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Buying a garage\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Buying a holiday home / land\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Buying a home\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Buying a new car\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Buying a used car\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Car repairs\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Education\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Everyday expenses\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Furniture\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Gasification / water supply\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Hobby\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Journey\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Medicine\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Money for a third person\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Other\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Payments on other loans\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Purchase of electronic equipment\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Refusal to name the goal\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Repairs\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Urgent needs\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_Wedding / gift / holiday\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_XAP\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CASH_LOAN_PURPOSE_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CONTRACT_STATUS_Approved\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CONTRACT_STATUS_Canceled\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CONTRACT_STATUS_Refused\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CONTRACT_STATUS_Unused offer\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PAYMENT_TYPE_Cash through the bank\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PAYMENT_TYPE_Cashless from the account of the employer\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PAYMENT_TYPE_Non-cash from your account\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PAYMENT_TYPE_XNA\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_CLIENT\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_HC\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_LIMIT\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_SCO\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_SCOFR\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_SYSTEM\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_VERIF\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_XAP\":[\"sum\", \"mean\"],\n",
    "                \"CODE_REJECT_REASON_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_TYPE_SUITE_alone\":[\"sum\", \"mean\"],\n",
    "                \"NAME_TYPE_SUITE_not_alone\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CLIENT_TYPE_New\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CLIENT_TYPE_Refreshed\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CLIENT_TYPE_Repeater\":[\"sum\", \"mean\"],\n",
    "                \"NAME_CLIENT_TYPE_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Audio/Video\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Clothing and Accessories\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Computers\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Construction Materials\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Consumer Electronics\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Furniture\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Mobile\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_Photo / Cinema Equipment\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_GOODS_CATEGORY_others\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PORTFOLIO_Cards\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PORTFOLIO_Cars\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PORTFOLIO_Cash\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PORTFOLIO_POS\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PORTFOLIO_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PRODUCT_TYPE_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PRODUCT_TYPE_walk-in\":[\"sum\", \"mean\"],\n",
    "                \"NAME_PRODUCT_TYPE_x-sell\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_AP+ (Cash loan)\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_Car dealer\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_Channel of corporate sales\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_Contact center\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_Country-wide\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_Credit and cash offices\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_Regional / Local\":[\"sum\", \"mean\"],\n",
    "                \"CHANNEL_TYPE_Stone\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_Clothing\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_Connectivity\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_Construction\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_Consumer electronics\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_Furniture\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_Industry\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_SELLER_INDUSTRY_others\":[\"sum\", \"mean\"],\n",
    "                \"NAME_YIELD_GROUP_XNA\":[\"sum\", \"mean\"],\n",
    "                \"NAME_YIELD_GROUP_high\":[\"sum\", \"mean\"],\n",
    "                \"NAME_YIELD_GROUP_low_action\":[\"sum\", \"mean\"],\n",
    "                \"NAME_YIELD_GROUP_low_normal\":[\"sum\", \"mean\"],\n",
    "                \"NAME_YIELD_GROUP_middle\":[\"sum\", \"mean\"],\n",
    "                \"NEW_CHURN_PREV_0\":[\"sum\", \"mean\"],\n",
    "                \"NEW_CHURN_PREV_1\":[\"sum\", \"mean\"],\n",
    "                \"NEW_CHURN_PREV_NaN\":[\"sum\", \"mean\"]}\n",
    "\n",
    "    prev_agg_list.update(agg_list_previous_application)\n",
    "    \n",
    "    \n",
    "    return prev_agg_list, df_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_and_combine():\n",
    "\n",
    "    \n",
    "    with timer(\"Process application train\"):\n",
    "        df = application_train()\n",
    "        print(\"application train & test shape:\", df.shape)\n",
    "        \n",
    "    \n",
    "    with timer(\"Bureau and Bureau Balance\"):\n",
    "        bureau_and_bb_agg = bureau_bb()\n",
    "        print(\"Bureau and Bureau Balance:\", bureau_and_bb_agg.shape)\n",
    "        \n",
    "    with timer(\"Installment Payments\"):\n",
    "        agg_list_previous_application, ins_agg = installments_payments()\n",
    "        print(\"Installment Payments:\", ins_agg.shape)    \n",
    "    \n",
    "    with timer(\"Pos Cash Balance\"):\n",
    "        agg_list_previous_application, pos_agg = pos_cash_balance(agg_list_previous_application)\n",
    "        print(\"Pos Cash Balance:\", pos_agg.shape)  \n",
    "        \n",
    "    \n",
    "    with timer(\"Credit Card Balance\"):\n",
    "        CCB_agg = credit_card_balance()\n",
    "        print(\"Credit Card Balance:\", CCB_agg.shape) \n",
    "    \n",
    "    with timer(\"previous_application\"):\n",
    "        prev_agg_list, df_prev = previous_application(agg_list_previous_application)\n",
    "        print(\"previous_application:\", df_prev.shape) \n",
    "        \n",
    "        \n",
    "    with timer(\"All tables are combining\"):\n",
    "        df_prev_ins = df_prev.merge(ins_agg, how = 'left', on = 'SK_ID_PREV')\n",
    "        df_prev_ins_pos = df_prev_ins.merge(pos_agg, how = 'left', on = 'SK_ID_PREV')\n",
    "        df_prev_ins_pos_agg = df_prev_ins_pos.groupby(\"SK_ID_CURR\").agg(prev_agg_list).reset_index()\n",
    "        df_prev_ins_pos_agg.columns = pd.Index([\"PREV_\" + col[0] + \"_\" + col[1].upper() for col in df_prev_ins_pos_agg.columns.tolist()])\n",
    "        df_prev_ins_pos_agg.rename(columns={\"PREV_SK_ID_CURR_\":\"SK_ID_CURR\"}, inplace = True)\n",
    "        #prev_son ile ana tablo\n",
    "        df_prev_others = df.merge(df_prev_ins_pos_agg, how = 'left',on = 'SK_ID_CURR')\n",
    "    \n",
    "        #credit_card_balance\n",
    "        df_prev_ins_pos_ccb = df_prev_others.merge(CCB_agg, how = 'left',on = 'SK_ID_CURR')\n",
    "    \n",
    "        #bureau_balance\n",
    "        all_data = df_prev_ins_pos_ccb.merge(bureau_and_bb_agg, how = 'left',on = 'SK_ID_CURR')\n",
    "        \n",
    "        print(\"all_data process:\", all_data.shape) \n",
    "\n",
    "    \n",
    "    \n",
    "    return all_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgbm = LGBMClassifier()\n",
    "\n",
    "#lgbm_params = {\"learning_rate\": [0.001, 0.01, 0.1],\n",
    "#              \"n_estimators\": [200, 500, 100],\n",
    "#              \"max_depth\":[1,2,35,8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = all_data[all_data['TARGET'].notnull()]\n",
    "#y_train = train[\"TARGET\"]\n",
    "#X_train = train.drop(\"TARGET\", axis = 1)\n",
    "\n",
    "#lgbm_cv_model = GridSearchCV(lgbm,lgbm_params, cv = 10, n_jobs = -1, verbose = 4).fit(X_train, y_train)\n",
    "#lgbm_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(all_data):\n",
    "\n",
    "    train_df = all_data[all_data['TARGET'].notnull()]\n",
    "    test_df = all_data[all_data['TARGET'].isnull()]\n",
    "\n",
    "    folds = KFold(n_splits = 10, shuffle = True, random_state = 1001)\n",
    "\n",
    "    oof_preds = np.zeros(train_df.shape[0])\n",
    "    sub_preds = np.zeros(test_df.shape[0])\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR']]\n",
    "\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['TARGET'])):\n",
    "\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df['TARGET'].iloc[train_idx]\n",
    "\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df['TARGET'].iloc[valid_idx]\n",
    "\n",
    "        clf = LGBMClassifier(\n",
    "                n_jobs = -1,\n",
    "                n_estimators=10000,\n",
    "                learning_rate=0.02,\n",
    "                num_leaves=34,\n",
    "                colsample_bytree=0.9497036,\n",
    "                subsample=0.8715623,\n",
    "                max_depth=8,\n",
    "                reg_alpha=0.041545473,\n",
    "                reg_lambda=0.0735294,\n",
    "                min_split_gain=0.0222415,\n",
    "                min_child_weight=39.3259775,\n",
    "                silent=-1,\n",
    "                verbose=-1, )\n",
    "\n",
    "        clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)], \n",
    "                eval_metric = 'auc', verbose = 200, early_stopping_rounds = 200)\n",
    "\n",
    "        #y_pred_valid\n",
    "        oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        sub_preds += clf.predict_proba(test_df[feats], num_iteration=clf.best_iteration_)[:, 1] / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "\n",
    "        print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx]))) \n",
    "\n",
    "\n",
    "    print('Full AUC score %.6f' % roc_auc_score(train_df['TARGET'], oof_preds)) #y_pred_valid   \n",
    "\n",
    "    test_df['TARGET'] = sub_preds\n",
    "    test_df[['SK_ID_CURR', 'TARGET']].to_csv(\"dsmlbc1_submission.csv\", index= False)\n",
    "\n",
    "    display_importances(feature_importance_df)\n",
    "    \n",
    "    return feature_importance_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    with timer(\"Preprocessing Time\"):\n",
    "        all_data = pre_processing_and_combine()\n",
    "    \n",
    "    with timer(\"Modeling\"):\n",
    "        feat_importance = modeling(all_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with timer(\"Full model run\"):\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dsmlbc1_ws: 2115s\n",
    "# dsmlbc1_submission: 0.79441"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}